{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import models\n",
    "from utils.training import train_meta_model, train_gp\n",
    "from utils.gp_data import obtain_me_a_nice_gp_dataset_please\n",
    "from utils.data_utils import ctxt_trgt_split\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 1000\n",
    "md = []\n",
    "# data_hypers = {'l': 1.0, 'kernel': 'per', 'p': 1}\n",
    "data_hypers = {'l': 0.5, 'kernel': 'se'}\n",
    "for _ in range(num_datasets):\n",
    "    X, y = obtain_me_a_nice_gp_dataset_please(n_range=[10, 100], **data_hypers)\n",
    "    md.append((X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lik = models.GaussianLikelihood(sigma_y = 0.05, train_sigma_y=False)\n",
    "# # prior = sparse_gp.GPPrior(covariance_function='periodic', num_inputs=1, train_l=True, train_p=True, p=0.5)\n",
    "# prior = models.GPPrior(covariance_function='squared-exponential', train_l=True)\n",
    "# num_induc = 32\n",
    "# use_titsias = False\n",
    "# sgnp = models.SparseGaussianNeuralProcess(\n",
    "#     x_dim=1,\n",
    "#     num_inducing=num_induc,\n",
    "#     likelihood=lik,\n",
    "#     prior=prior,\n",
    "#     cnn_hidden_chans=[32, 32, 32], # ignored if using unet or titsias\n",
    "#     cnn_kernel_size=5,\n",
    "#     d_k=8,\n",
    "#     Z_net_width=32,\n",
    "#     Z_net_hidden_depth=2,\n",
    "#     use_transformer=True,\n",
    "#     nonlinearity=torch.nn.ReLU(),\n",
    "#     use_titsias=use_titsias,\n",
    "#     grid_spacing=2e-2,\n",
    "#     init_cds_ls_multiplier=2,\n",
    "#     # use_unet=True,\n",
    "#     # meta_learn_hypers=['l']\n",
    "# )\n",
    "\n",
    "\n",
    "gnp = models.ConvGNP(\n",
    "    x_dim=1,\n",
    "    cnn_hidden_chans=[32, 32, 32],\n",
    "    cnn_kernel_size=5,\n",
    "    d_k=8,\n",
    "    nonlinearity=torch.nn.ReLU(),\n",
    "    grid_spacing=2e-2,\n",
    "    init_ls_multiplier=1,\n",
    "    # use_unet=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_metrics = train_meta_model(\n",
    "#     sgnp,\n",
    "#     md,\n",
    "#     training_steps=20_000,\n",
    "#     batch_size=5,\n",
    "#     learning_rate=1e-4,\n",
    "#     final_learning_rate=5e-5,\n",
    "#     num_samples=5,\n",
    "#     loss_function='vi',\n",
    "# )\n",
    "\n",
    "training_metrics = train_meta_model(\n",
    "    gnp,\n",
    "    md,\n",
    "    training_steps=20_000,\n",
    "    batch_size=5,\n",
    "    learning_rate=1e-3,\n",
    "    final_learning_rate=5e-5,\n",
    "    loss_function='npml',\n",
    "    include_ctxt_in_trgt=True,\n",
    "    # ctxt_proportion_range=(0.05, 0.5),  # for simple data\n",
    "    ctxt_proportion_range=(0.25, 0.75)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(training_metrics), figsize=(3*len(training_metrics), 1))\n",
    "if not isinstance(axes, list):\n",
    "    axes = [axes]\n",
    "omitted_steps = 50\n",
    "for i, (key, value) in enumerate(training_metrics.items()):\n",
    "    axes[i].plot(value[omitted_steps:])\n",
    "    axes[i].set_xlabel(key)\n",
    "    axes[i].grid()\n",
    "    axes[i].set_ylim([-100, 400])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(12)\n",
    "X, y = obtain_me_a_nice_gp_dataset_please(n_range=[5, 30], **data_hypers)\n",
    "shift = 0.0\n",
    "# X, y =  md[torch.randint(0, len(md), (1,)).item()]\n",
    "X_c, y_c = X.clone(), y.clone()\n",
    "\n",
    "xs = torch.linspace(-5.0, 5.0, 500).unsqueeze(-1)\n",
    "X_c += shift\n",
    "xs += shift\n",
    "with torch.no_grad():\n",
    "    # preds = sgnp(xs, X_c, y_c)\n",
    "    preds = gnp(X_c, y_c, xs)\n",
    "\n",
    "if isinstance(preds, torch.distributions.MultivariateNormal):\n",
    "    mu = preds.mean\n",
    "    sig = preds.variance.sqrt()\n",
    "elif isinstance(preds, torch.distributions.Normal):\n",
    "    mu = preds.mean\n",
    "    sig = preds.scale\n",
    "\n",
    "# plt.fill_between(xs.squeeze(), mu - 2*sig, mu + 2*sig, alpha=0.9)\n",
    "cont_gran = 200\n",
    "for cont in range(cont_gran):\n",
    "    c = cont / cont_gran\n",
    "    plt.fill_between(xs.squeeze(), mu-2*c*sig, mu+2*c*sig, color='black', alpha=0.03*(1-c)**2)\n",
    "plt.scatter(X_c, y_c, color='C1', zorder=10000)\n",
    "plt.scatter(X_c, y_c)\n",
    "plt.grid()\n",
    "plt.xlim([-4.0+shift, 4.0+shift])\n",
    "plt.ylim([-2.0, 2.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_prior = sparse_gp.GPPrior(covariance_function='periodic', train_l=True, train_p=True)\n",
    "gp_prior = models.GPPrior(covariance_function='squared-exponential', train_l=True)\n",
    "gp = models.GaussianProcess(num_inputs=1, prior=gp_prior, train_sigma_y=True)\n",
    "\n",
    "gp_training_metrics = train_gp(\n",
    "    gp,\n",
    "    X_c,\n",
    "    y_c,\n",
    "    epochs=5_000,\n",
    "    learning_rate=1e-2,\n",
    "    final_learning_rate=1e-3\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(gp_training_metrics), figsize=(3*len(gp_training_metrics), 1))\n",
    "# if not isinstance(axes, list):\n",
    "#     axes = [axes]\n",
    "omitted_steps = 50\n",
    "for i, (key, value) in enumerate(gp_training_metrics.items()):\n",
    "    axes[i].plot(value[omitted_steps:])\n",
    "    axes[i].set_xlabel(key)\n",
    "    axes[i].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = gp(xs, X_c, y_c, multivariate=False)\n",
    "mu = preds.mean\n",
    "sig = preds.variance.sqrt()\n",
    "\n",
    "# plt.fill_between(xs.squeeze(), mu - 2*sig, mu + 2*sig, alpha=0.9)\n",
    "cont_gran = 200\n",
    "for cont in range(cont_gran):\n",
    "    c = cont / cont_gran\n",
    "    plt.fill_between(xs.squeeze(), mu-2*c*sig, mu+2*c*sig, color='black', alpha=0.03*(1-c)**2)\n",
    "plt.scatter(X_c, y_c, color='C1', zorder=10000)\n",
    "plt.scatter(X_c, y_c)\n",
    "plt.grid()\n",
    "plt.xlim([-4.0+shift, 4.0+shift])\n",
    "plt.ylim([-2.0, 2.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_sets = 100\n",
    "per_point_lls = torch.zeros((num_test_sets))\n",
    "\n",
    "\n",
    "for i in tqdm(range(num_test_sets), disable=False):\n",
    "    torch.manual_seed(i)\n",
    "    X, y,  = obtain_me_a_nice_gp_dataset_please(n_range=[5, 30], **data_hypers)\n",
    "    X_c, y_c, X_t, y_t = ctxt_trgt_split(X, y, ctxt_proportion_range=[0.45, 0.55])\n",
    "\n",
    "    # gp_prior = sparse_gp.GPPrior(covariance_function='squared-exponential', l=0.5, train_l=False)\n",
    "    # gp = sparse_gp.GaussianProcess(num_inputs=1, prior=gp_prior, train_sigma_y=False, sigma_y=0.05)\n",
    "\n",
    "    # _ = train_gp(\n",
    "    #         gp,\n",
    "    #         X_c,\n",
    "    #         y_c,\n",
    "    #         epochs=5_000,\n",
    "    #         learning_rate=5e-3,\n",
    "    #         final_learning_rate=1e-3,\n",
    "    #         silent=True\n",
    "    #     )\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # predictive = sgnp(X_t, X_c, y_c, multivariate=True)\n",
    "        # per_point_lls[i] = predictive.log_prob(y_t.squeeze()) / y_t.shape[0]\n",
    "\n",
    "        predictive = gnp(X_c, y_c, X_t)\n",
    "        per_point_lls[i] = predictive.log_prob(y_t.squeeze()) / y_t.shape[0]\n",
    "\n",
    "        # predictive = gp(X_t, X_c, y_c, multivariate=True)\n",
    "        # per_point_lls[i] = predictive.log_prob(y_t.squeeze()) / y_t.shape[0]\n",
    "\n",
    "\n",
    "print(per_point_lls.mean(), per_point_lls.std()/10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
